{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import random\n",
    "import copy\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, Dropout, Embedding\n",
    "from keras.layers import GlobalAveragePooling1D, concatenate, CuDNNLSTM, Conv1D,BatchNormalization\n",
    "from keras.layers.core import SpatialDropout1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Input, LSTM, Bidirectional, Conv1D\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_pre2.csv')\n",
    "test = pd.read_csv('test_pre2.csv')\n",
    "subm = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = train[\"comment_text\"].fillna(\"fillna\").values\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y_train_list = train[list_classes].values\n",
    "X_test_list = test[\"comment_text\"].fillna(\"fillna\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 100000\n",
    "max_len = 150\n",
    "embed_size=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train_list) + list(X_test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequences = tokenizer.texts_to_sequences(X_train_list)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequences_pad = sequence.pad_sequences(X_train_sequences, maxlen=max_len)\n",
    "X_test_sequences_pad = sequence.pad_sequences(X_test_sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words = min(max_features, len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vec = 'crawl-300d-2M.vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(embedding_vec, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 300)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix_fast_text = np.zeros((nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = model[word] if word in model else None\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix_fast_text[i] = embedding_vector\n",
    "embedding_matrix_fast_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_glove = 'glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_index_glove = {}\n",
    "with open(embedding_glove,encoding ='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        cof = np.asarray(values[1:],dtype = 'float32')\n",
    "        embedding_index_glove[word] = cof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_glove = np.zeros((nb_words,embed_size))\n",
    "for word,i in word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vec_glove = embedding_index_glove.get(word)\n",
    "    if embedding_vec_glove is not None:\n",
    "        embedding_matrix_glove[i] = embedding_vec_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix_glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import initializers\n",
    "from keras.engine import InputSpec, Layer\n",
    "from keras import backend as K\n",
    "\n",
    "class AttentionWeightedAverage(Layer):\n",
    "\n",
    "    def __init__(self, return_attention=False, **kwargs):\n",
    "        self.init = initializers.get('uniform')\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=self.init)\n",
    "        self.trainable_weights = [self.W]\n",
    "        super(AttentionWeightedAverage, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # computes a probability distribution over the timesteps\n",
    "        # uses 'max trick' for numerical stability\n",
    "        # reshape is done to avoid issue with Tensorflow\n",
    "        # and 1-dimensional weights\n",
    "        logits = K.dot(x, self.W)\n",
    "        x_shape = K.shape(x)\n",
    "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
    "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
    "\n",
    "        # masked timesteps have zero weight\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            ai = ai * mask\n",
    "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
    "        weighted_input = x * K.expand_dims(att_weights)\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "        if self.return_attention:\n",
    "            return [result, att_weights]\n",
    "        return result\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return self.compute_output_shape(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[2]\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
    "        return (input_shape[0], output_len)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        if isinstance(input_mask, list):\n",
    "            return [None] * len(input_mask)\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    #filter_sizes = [3,4,5]\n",
    "    #num_filters =64\n",
    "    inp = Input(shape=(max_len,))\n",
    "    \n",
    "    x = Embedding(max_features,embed_size,weights=[embedding_matrix_fast_text],trainable = False)(inp)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    \n",
    "    lstm1 = Bidirectional(CuDNNLSTM(100, return_sequences=True, name = 'bilstm1'))(x)\n",
    "    \n",
    "    lstm2 = Bidirectional(CuDNNLSTM(100, return_sequences=True, return_state = True, name = 'bigru2'))(lstm1)\n",
    "    conc = concatenate([lstm2[0], lstm1, x])\n",
    "    \n",
    "    x2 = Conv1D(64, kernel_size=2, padding=\"same\", activation = 'relu',name = '2gram_conv')(conc)\n",
    "    katt2 = AttentionWeightedAverage(name='2gram_att')(x2)\n",
    "    \n",
    "    x5 = Conv1D(64,kernel_size = 5, padding = 'same',activation = 'relu', name = '5gram_conv')(conc)\n",
    "    katt5 = AttentionWeightedAverage(name='5gram_att')(x5)    \n",
    "    cov = concatenate([katt2,katt5])\n",
    "    \n",
    "    x = BatchNormalization()(cov)\n",
    "    x = Dense(50, activation = 'relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    out = Dense(6, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inp, out)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mskf = MultilabelStratifiedKFold(n_splits= 10, random_state=423)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"auto\", patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 150, 150) (?, 150, 300) (?, 150, 150)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 150, 300)     30000000    input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_20 (SpatialDr (None, 150, 300)     0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_36 (Bidirectional (None, 150, 150)     226200      spatial_dropout1d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_37 (Bidirectional [(None, 150, 150), ( 136200      bidirectional_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 150, 600)     0           bidirectional_37[0][0]           \n",
      "                                                                 bidirectional_36[0][0]           \n",
      "                                                                 spatial_dropout1d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "2gram_conv (Conv1D)             (None, 150, 64)      76864       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "5gram_conv (Conv1D)             (None, 150, 64)      192064      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "2gram_att (AttentionWeightedAve (None, 64)           64          2gram_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "5gram_att (AttentionWeightedAve (None, 64)           64          5gram_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 128)          0           2gram_att[0][0]                  \n",
      "                                                                 5gram_att[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128)          512         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 50)           6450        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 50)           200         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 6)            306         batch_normalization_8[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 30,638,924\n",
      "Trainable params: 638,568\n",
      "Non-trainable params: 30,000,356\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "'''val_loss = []\n",
    "for i in drop_list:'''\n",
    "model1 = get_model()\n",
    "print(model1.summary())\n",
    "\n",
    "#val_loss.append(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_nums, 143614 test_nums: 15957\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/50\n",
      " - 144s - loss: 0.0273 - acc: 0.9890 - val_loss: 0.0293 - val_acc: 0.9881\n",
      "Epoch 2/50\n",
      " - 144s - loss: 0.0267 - acc: 0.9893 - val_loss: 0.0295 - val_acc: 0.9879\n",
      "Epoch 3/50\n",
      " - 144s - loss: 0.0261 - acc: 0.9895 - val_loss: 0.0319 - val_acc: 0.9874\n",
      "Epoch 4/50\n",
      " - 144s - loss: 0.0256 - acc: 0.9897 - val_loss: 0.0321 - val_acc: 0.9873\n",
      "train_nums, 143614 test_nums: 15957\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/50\n",
      " - 144s - loss: 0.0264 - acc: 0.9896 - val_loss: 0.0199 - val_acc: 0.9925\n",
      "Epoch 2/50\n",
      " - 144s - loss: 0.0255 - acc: 0.9898 - val_loss: 0.0221 - val_acc: 0.9914\n",
      "Epoch 3/50\n",
      " - 144s - loss: 0.0248 - acc: 0.9900 - val_loss: 0.0218 - val_acc: 0.9913\n",
      "Epoch 4/50\n",
      " - 144s - loss: 0.0247 - acc: 0.9900 - val_loss: 0.0222 - val_acc: 0.9912\n",
      "train_nums, 143614 test_nums: 15957\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/50\n",
      " - 143s - loss: 0.0245 - acc: 0.9901 - val_loss: 0.0184 - val_acc: 0.9934\n",
      "Epoch 2/50\n",
      " - 144s - loss: 0.0237 - acc: 0.9905 - val_loss: 0.0185 - val_acc: 0.9927\n",
      "Epoch 3/50\n",
      " - 144s - loss: 0.0233 - acc: 0.9907 - val_loss: 0.0200 - val_acc: 0.9923\n",
      "Epoch 4/50\n",
      " - 144s - loss: 0.0226 - acc: 0.9909 - val_loss: 0.0194 - val_acc: 0.9921\n",
      "train_nums, 143614 test_nums: 15957\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/50\n",
      " - 143s - loss: 0.0226 - acc: 0.9909 - val_loss: 0.0163 - val_acc: 0.9936\n",
      "Epoch 2/50\n",
      " - 143s - loss: 0.0222 - acc: 0.9911 - val_loss: 0.0165 - val_acc: 0.9938\n",
      "Epoch 3/50\n",
      " - 144s - loss: 0.0216 - acc: 0.9914 - val_loss: 0.0180 - val_acc: 0.9929\n",
      "Epoch 4/50\n",
      " - 144s - loss: 0.0212 - acc: 0.9915 - val_loss: 0.0208 - val_acc: 0.9916\n",
      "train_nums, 143613 test_nums: 15958\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/50\n",
      " - 145s - loss: 0.0214 - acc: 0.9914 - val_loss: 0.0132 - val_acc: 0.9955\n",
      "Epoch 2/50\n",
      " - 143s - loss: 0.0206 - acc: 0.9917 - val_loss: 0.0141 - val_acc: 0.9948\n",
      "Epoch 3/50\n",
      " - 143s - loss: 0.0201 - acc: 0.9920 - val_loss: 0.0152 - val_acc: 0.9945\n",
      "Epoch 4/50\n",
      " - 143s - loss: 0.0196 - acc: 0.9921 - val_loss: 0.0148 - val_acc: 0.9943\n",
      "train_nums, 143614 test_nums: 15957\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/50\n",
      " - 143s - loss: 0.0199 - acc: 0.9921 - val_loss: 0.0117 - val_acc: 0.9964\n",
      "Epoch 2/50\n",
      " - 143s - loss: 0.0193 - acc: 0.9923 - val_loss: 0.0129 - val_acc: 0.9954\n",
      "Epoch 3/50\n",
      " - 143s - loss: 0.0189 - acc: 0.9924 - val_loss: 0.0127 - val_acc: 0.9953\n",
      "Epoch 4/50\n",
      " - 143s - loss: 0.0185 - acc: 0.9926 - val_loss: 0.0139 - val_acc: 0.9948\n",
      "train_nums, 143614 test_nums: 15957\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/50\n",
      " - 143s - loss: 0.0184 - acc: 0.9926 - val_loss: 0.0113 - val_acc: 0.9965\n",
      "Epoch 2/50\n",
      " - 143s - loss: 0.0180 - acc: 0.9929 - val_loss: 0.0120 - val_acc: 0.9959\n",
      "Epoch 3/50\n",
      " - 143s - loss: 0.0176 - acc: 0.9930 - val_loss: 0.0124 - val_acc: 0.9956\n",
      "Epoch 4/50\n",
      " - 144s - loss: 0.0172 - acc: 0.9932 - val_loss: 0.0136 - val_acc: 0.9952\n",
      "train_nums, 143614 test_nums: 15957\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/50\n",
      " - 145s - loss: 0.0173 - acc: 0.9932 - val_loss: 0.0107 - val_acc: 0.9966\n",
      "Epoch 2/50\n",
      " - 145s - loss: 0.0172 - acc: 0.9932 - val_loss: 0.0113 - val_acc: 0.9962\n",
      "Epoch 3/50\n",
      " - 144s - loss: 0.0167 - acc: 0.9934 - val_loss: 0.0122 - val_acc: 0.9956\n",
      "Epoch 4/50\n",
      " - 145s - loss: 0.0162 - acc: 0.9935 - val_loss: 0.0135 - val_acc: 0.9953\n",
      "train_nums, 143614 test_nums: 15957\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/50\n",
      " - 145s - loss: 0.0164 - acc: 0.9936 - val_loss: 0.0078 - val_acc: 0.9976\n",
      "Epoch 2/50\n",
      " - 145s - loss: 0.0158 - acc: 0.9938 - val_loss: 0.0094 - val_acc: 0.9971\n",
      "Epoch 3/50\n",
      " - 145s - loss: 0.0154 - acc: 0.9938 - val_loss: 0.0091 - val_acc: 0.9969\n",
      "Epoch 4/50\n",
      " - 145s - loss: 0.0149 - acc: 0.9941 - val_loss: 0.0106 - val_acc: 0.9962\n",
      "train_nums, 143614 test_nums: 15957\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/50\n",
      " - 144s - loss: 0.0152 - acc: 0.9940 - val_loss: 0.0087 - val_acc: 0.9976\n",
      "Epoch 2/50\n",
      " - 144s - loss: 0.0149 - acc: 0.9941 - val_loss: 0.0099 - val_acc: 0.9970\n",
      "Epoch 3/50\n",
      " - 144s - loss: 0.0146 - acc: 0.9943 - val_loss: 0.0098 - val_acc: 0.9970\n",
      "Epoch 4/50\n",
      " - 145s - loss: 0.0142 - acc: 0.9944 - val_loss: 0.0097 - val_acc: 0.9969\n"
     ]
    }
   ],
   "source": [
    "subs = []\n",
    "for train_index,text_index in mskf.split(X_train_sequences_pad,y_train_list):        \n",
    "    print('train_nums,',len(train_index),'test_nums:',len(text_index))\n",
    "    train_x,text_x = X_train_sequences_pad[train_index],X_train_sequences_pad[text_index]\n",
    "    train_y,text_y = y_train_list[train_index],y_train_list[text_index]\n",
    "    hist = model1.fit(train_x,train_y,batch_size = 256,epochs = 50,validation_data = (text_x,text_y), verbose = 2,callbacks = [early])\n",
    "        \n",
    "    #result = model1.predict(text_x,batch_size = 256)\n",
    "    #s = roc_auc_score(text_y,result)\n",
    "    #print('roc_auc_score:',s)\n",
    "        \n",
    "    '''tpd = pd.DataFrame(columns=[['id']+list_classes])\n",
    "    tpd[list_classes] = result\n",
    "    tpd ['id'] = text_index\n",
    "    text_cnn_result.append(tpd)'''\n",
    "        \n",
    "    sub = model1.predict(X_test_sequences_pad,batch_size = 256)\n",
    "        \n",
    "    if len(subs) == 0:\n",
    "        subs = sub\n",
    "    else:\n",
    "        subs +=sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = subs/10\n",
    "subm[list_classes] = subs\n",
    "subm.to_csv(\"bilstm_cnn_mask_sub.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/50\n",
      " - 196s - loss: 0.0364 - acc: 0.9856 - val_loss: 0.0411 - val_acc: 0.9843\n",
      "Epoch 2/50\n",
      " - 196s - loss: 0.0354 - acc: 0.9859 - val_loss: 0.0421 - val_acc: 0.9840\n",
      "Epoch 3/50\n",
      " - 195s - loss: 0.0350 - acc: 0.9861 - val_loss: 0.0420 - val_acc: 0.9841\n",
      "Epoch 4/50\n",
      " - 196s - loss: 0.0344 - acc: 0.9864 - val_loss: 0.0411 - val_acc: 0.9844\n",
      "Epoch 5/50\n",
      " - 196s - loss: 0.0335 - acc: 0.9866 - val_loss: 0.0410 - val_acc: 0.9839\n",
      "Epoch 6/50\n",
      " - 196s - loss: 0.0329 - acc: 0.9869 - val_loss: 0.0417 - val_acc: 0.9842\n",
      "Epoch 7/50\n",
      " - 196s - loss: 0.0320 - acc: 0.9870 - val_loss: 0.0424 - val_acc: 0.9838\n",
      "Epoch 8/50\n",
      " - 196s - loss: 0.0313 - acc: 0.9874 - val_loss: 0.0446 - val_acc: 0.9828\n",
      "Epoch 9/50\n",
      " - 195s - loss: 0.0308 - acc: 0.9876 - val_loss: 0.0430 - val_acc: 0.9834\n",
      "Epoch 10/50\n",
      " - 196s - loss: 0.0303 - acc: 0.9879 - val_loss: 0.0460 - val_acc: 0.9826\n"
     ]
    }
   ],
   "source": [
    "#hist = model1.fit(X_train_sequences_pad,y_train_list,batch_size = 128,epochs = 50,validation_split = 0.1, verbose = 2,callbacks = [early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss = hist.history['val_loss']\n",
    "plt.plot(val_loss)\n",
    "plt.xlabel('Times')\n",
    "plt.ylabel('Val_Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
